{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNuR/W6glD5HrWamGEVys9v",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NidhaK/calculator/blob/main/Untitled3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "def preprocess_text(text):\n",
        "    words = word_tokenize(text.lower())\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    words = [word for word in words if word.isalnum() and word not in stop_words]\n",
        "\n",
        "    stemmer = PorterStemmer()\n",
        "    words = [stemmer.stem(word) for word in words]\n",
        "\n",
        "    return ' '.join(words)\n",
        "\n",
        "def text_summarizer(text, num_sentences=2):\n",
        "    preprocessed_text = preprocess_text(text)\n",
        "\n",
        "    sentences = sent_tokenize(preprocessed_text)\n",
        "\n",
        "    tfidf_vectorizer = TfidfVectorizer()\n",
        "    tfidf_matrix = tfidf_vectorizer.fit_transform(sentences)\n",
        "\n",
        "    sentence_scores = tfidf_matrix.toarray().sum(axis=1)\n",
        "\n",
        "    top_sentence_indices = sentence_scores.argsort()[-num_sentences:][::-1]\n",
        "\n",
        "    top_sentence_indices.sort()\n",
        "\n",
        "    summarized_text = ' '.join([sentences[i] for i in top_sentence_indices])\n",
        "\n",
        "    return summarized_text\n",
        "user_input = input(\"Enter the text you want to summarize:\\n\")\n",
        "\n",
        "summary = text_summarizer(user_input)\n",
        "print(\"\\nSummary:\")\n",
        "print(summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XkfSK3CY7TUM",
        "outputId": "c9970725-677b-4871-850c-3e8aa45805f7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the text you want to summarize:\n",
            "the use and development of computer systems that are able to learn and adapt without following explicit instructions, by using algorithms and statistical models to analyse and draw inferences from patterns in data:\n",
            "\n",
            "Summary:\n",
            "use develop comput system abl learn adapt without follow explicit instruct use algorithm statist model analys draw infer pattern data\n"
          ]
        }
      ]
    }
  ]
}